http://en.wikipedia.org/wiki/British_National_Corpus
BulNet by http://ibl.bas.bg & by http://bacl.bg & independent-researcher&private-consultant contributors working with scanned&OCR'd print books & in/at big local & national libraries&reading-room book-clubs (читалища)

https://www.ssa.gov/OACT/babynames/
https://www.ssa.gov/oact/babynames/limits.html
https://www.ssa.gov/agency/plain-language/

https://github.com/sahwar/fastText
https://commoncrawl.org/
https://fasttext.cc/docs/en/english-vectors.html

http://ngrams.googlelabs.com/datasets

https://github.com/TimeMagazineLabs/babynames
https://www.ssa.gov/OACT/babynames/

https://github.com/collections/open-journalism

(VARIOUS, EN, BG) http://www.wiksearch.com/ (an experimental interface for searching through Wikipedia.org)
(VARIOUS, EN, BG, NON-DICT, WORDLIST_GENERATE_FROM) https://dumps.wikimedia.org/ + https://dumps.wikimedia.org/other/pagecounts-raw/ + https://old.datahub.io/organization/wikimedia

...
text corpuses pasted on http://github.com & http://gitlab.org & on private self-hosted overseas (Ireland, France, the Netherlands, Switzerland, etc.) Gitea git-repositories, etc.
http://ngram.google.com (Google Ngrams & Google.com dictionary)
http://en.wikiquote.org
http://en.wiktionary.org
http://dumps.wikimedia.org

------

# EVEN MORE ENGLISH-LANGUAGE TEXT CORPORA

## Data sources

The Datamuse API leans on many freely available data sources to do its work:

*   **Phonetic data**: The [CMU pronouncing dictionary](http://www.speech.cs.cmu.edu/cgi-bin/cmudict) is used as a source of phonetic transcriptions for the "sounds\-like" constraint and for the various English\-language phonetic relations such as perfect rhymes and homophones. The "approximate rhymes" constraint ("rel\_nry") is based on this data as well as an analysis of lyrics and poetry on the Web (via the [Common Crawl](https://commoncrawl.org/)).
*   **Corpus\-based data**: The [Google Books Ngrams](http://storage.googleapis.com/books/ngrams/books/datasetsv2.html) data set is used to build the language model that scores candidate words by context, and also for some of the lexical relations. [word2vec](https://code.google.com/archive/p/word2vec/) is used for reranking result sets by topic (the "topics" parameter). word2vec as well as the excellent [Paraphrase Database](http://www.cis.upenn.edu/~ccb/ppdb/) are used to backfill the results for single\-word "means\-like" constraints (the "ml" parameter); in particular, the "XXL" lexical paraphrases are used, without modification.
*   **Semantic knowledge**: [WordNet 3.0](http://wordnet.princeton.edu) is used for several of the static semantic lexical relations. For the "means\-like" ("ml") constraint, dozens of online dictionaries crawled by [OneLook](https://onelook.com/) are used in addition to WordNet.


SOURCE:
https://www.datamuse.com/api/ ( http://archive.is/MjNaf )
